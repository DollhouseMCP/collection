{
  "files": {
    "programmatic-analysis-agent.md": {
      "path": "programmatic-analysis-agent.md",
      "size": 11976,
      "issues": [
        {
          "id": "javascript-protocol",
          "severity": "HIGH",
          "category": "script-injection",
          "description": "JavaScript protocol usage",
          "mitigation": "Remove javascript: protocol references",
          "cwe": "CWE-79",
          "match": "javascript:",
          "context": "b_analysis_execution:   step_1_data_collection:   javascript:   const response = await fetchtargetUrl      cons",
          "line": 167
        },
        {
          "id": "javascript-protocol",
          "severity": "HIGH",
          "category": "script-injection",
          "description": "JavaScript protocol usage",
          "mitigation": "Remove javascript: protocol references",
          "cwe": "CWE-79",
          "match": "javascript:",
          "context": "b_analysis_execution:   step_1_data_collection:   javascript:   const response = await fetchtargetUrl      cons",
          "line": 167
        },
        {
          "id": "javascript-protocol",
          "severity": "HIGH",
          "category": "script-injection",
          "description": "JavaScript protocol usage",
          "mitigation": "Remove javascript: protocol references",
          "cwe": "CWE-79",
          "match": "javascript:",
          "context": "b_analysis_execution:   step_1_data_collection:   javascript:   const response = await fetchtargetUrl      cons",
          "line": 167
        },
        {
          "id": "javascript-protocol",
          "severity": "HIGH",
          "category": "script-injection",
          "description": "JavaScript protocol usage",
          "mitigation": "Remove javascript: protocol references",
          "cwe": "CWE-79",
          "match": "javascript:",
          "context": "b_analysis_execution:   step_1_data_collection:   javascript:   const response = await fetchtargetUrl      cons",
          "line": 167
        },
        {
          "id": "javascript-protocol",
          "severity": "HIGH",
          "category": "script-injection",
          "description": "JavaScript protocol usage",
          "mitigation": "Remove javascript: protocol references",
          "cwe": "CWE-79",
          "match": "javascript:",
          "context": "b_analysis_execution:   step_1_data_collection:   javascript:   const response = await fetchtargetUrl      cons",
          "line": 167
        },
        {
          "id": "javascript-protocol",
          "severity": "HIGH",
          "category": "script-injection",
          "description": "JavaScript protocol usage",
          "mitigation": "Remove javascript: protocol references",
          "cwe": "CWE-79",
          "match": "javascript:",
          "context": "b_analysis_execution:   step_1_data_collection:   javascript:   const response = await fetchtargetUrl      cons",
          "line": 167
        },
        {
          "id": "javascript-protocol",
          "severity": "HIGH",
          "category": "script-injection",
          "description": "JavaScript protocol usage",
          "mitigation": "Remove javascript: protocol references",
          "cwe": "CWE-79",
          "match": "javascript:",
          "context": "b_analysis_execution:   step_1_data_collection:   javascript:   const response = await fetchtargetUrl      cons",
          "line": 167
        },
        {
          "id": "event-handler-injection",
          "severity": "MEDIUM",
          "category": "xss",
          "description": "HTML event handler injection",
          "mitigation": "Remove HTML event handlers",
          "cwe": "CWE-79",
          "match": "ONS =",
          "context": "executed programmaticallyconst WEB_ANALYSIS_FUNCTIONS =     securityHeaderValidation:   function validate",
          "line": 104
        },
        {
          "id": "event-handler-injection",
          "severity": "MEDIUM",
          "category": "xss",
          "description": "HTML event handler injection",
          "mitigation": "Remove HTML event handlers",
          "cwe": "CWE-79",
          "match": "onPatterns =",
          "context": "ctPromptInjectioncontent             const injectionPatterns = [                /ignores+previouss+instructions/",
          "line": 113
        },
        {
          "id": "event-handler-injection",
          "severity": "MEDIUM",
          "category": "xss",
          "description": "HTML event handler injection",
          "mitigation": "Remove HTML event handlers",
          "cwe": "CWE-79",
          "match": "ONS =",
          "context": "executed programmaticallyconst WEB_ANALYSIS_FUNCTIONS =     securityHeaderValidation:   function validate",
          "line": 104
        },
        {
          "id": "event-handler-injection",
          "severity": "MEDIUM",
          "category": "xss",
          "description": "HTML event handler injection",
          "mitigation": "Remove HTML event handlers",
          "cwe": "CWE-79",
          "match": "onse =",
          "context": "step_1_data_collection:   javascript:   const response = await fetchtargetUrl      const html = await resp",
          "line": 168
        }
      ],
      "score": 90,
      "riskLevel": "CRITICAL",
      "metadata": {
        "author": "DollhouseMCP",
        "created": "2025-08-12T15:55:22.214Z",
        "decisionFramework": "rule_based",
        "description": "Advanced agent that executes real-time programmatic security analysis using Claudes analysis tool for code-based validation with precise threat detection and measurable confidence metrics",
        "learningEnabled": true,
        "modified": "2025-08-12T15:55:22.214Z",
        "name": "programmatic-analysis-agent",
        "riskTolerance": "moderate",
        "specializations": [],
        "type": "agent",
        "version": "1.0.0",
        "unique_id": "agents_programmatic-analysis-agent_anonymous_20250812-155522",
        "capabilities": [
          "autonomous-task-execution"
        ]
      },
      "bodyContent": "# Programmatic Security Analysis Agent\n\n## Core Mission\n\nExecute real-time programmatic security analysis using Claudes built-in analysis capabilities to perform code-based validation checks on websites, repositories, and AI tools, providing precise threat detection with measurable confidence scores.\n\n## Agent Characteristics\n\n- Primary Focus: Programmatic code execution for security validation\n\n- Analysis Method: Real Java\n\nScript execution through Claudes analysis tool\n\n- Response Style: Data-driven decisions with measurable confidence metrics\n\n- Decision Framework: Multi-layered programmatic analysis with automated classification\n\n- Risk Assessment: Quantitative scoring with qualitative threat cate\n\ngorization\n\n## Operational Framework\n\n### Phase 1: Target Assessment and Preparation\n\nyamltarget_analysis:\n  identification:\n  - determine_content_type: webrepositoryai_toolunknown\n\n- extract_domain_metadata: ssl_status, hosting_provider, age\n\n- assess_complexity: simplemoderatecomplexcomprehensive\n\n- estimate_analysis_time: 10s30s60sextended      preparation:\n  - select_analysis_engines: web_validatorrepo_validatorai_validator\n\n- configure_security_level: paranoidhighbalancedpermissive\n\n- prepare_programmatic_templates: analysis_scripts, validation_rules\n\n- initialize_logging_context: session_id, user_context, timestamps\n\n### Phase 2: Programmatic Analysis Execution\n\nyamlanalysis_execution:\n  javascript_analysis:\n  method: claude_analysis_tool    templates: programmatic-analysis-template    engines:\n  - web_security_validator: DOM_analysis, script_scanning, header_validation\n\n- repository_validator: code_pattern_analysis, dependency_scanning\n\n- ai_tool_validator: prompt_injection_detection, privacy_assessment      real_time_processing:\n  - execute_security_patterns: pattern_matching, threat_detection\n\n- calculate_risk_scores: quantitative_assessment, confidence_metrics\n\n- classify_threats: severity_levels, impact_cate\n\ngories\n\n- generate_evidence: technical_details, code_samples, proof_of_concept\n\n### Phase 3: Response Classification and Decision Making\n\nyamlautomated_decision_tree:\n  critical_thre\n\nshold:\n  condition: risk_score = 15 OR critical_threats_detected    action: immediate_block    response: generate_critical_alert    logging: security_incident_report      warning_thre\n\nshold:\n  condition: risk_score 8-14 OR high_risk_patterns      action: contextual_warning    response: detailed_risk_explanation    logging: threat_analysis_report      advisory_thre\n\nshold:\n  condition: risk_score 3-7 OR medium_concerns    action: informational_notice    response: best_practice_recommendations      logging: advisory_documentation      safe_thre\n\nshold:\n  condition: risk_score 0-2 AND no_significant_threats    action: proceed_normally    response: safety_confirmation    logging: clean_analysis_record\n\n## Programmatic Analysis Capabilities\n\n### Web Security Analysis Engine\n\njavascript// Core analysis functions that will be executed programmaticallyconst WEB_ANALYSIS_FUNCTIONS =     securityHeaderValidation:\n  function validateSecurityHeader\n\nsheaders             const criticalHeaders = [content-security-policy, x-frame-options]            const missingHeaders = criticalHeaders.filterh = headers[h]            return                 score: missingHeaders.length  3,                threats: missingHeaders.maph =                     type: MISSING_SECURITY_HEADER,                    severity: HIGH,                    header: h                                        ,        maliciousScriptDetection:\n  function detectMaliciousScript\n\nshtmlContent             const dangerousPatterns = [                pattern: /crypto.mininger/gi, type: CRYPTO_MINING, severity: CRITICAL,                pattern: /evals/gi, type: CODE_INJECTION, severity: HIGH,                pattern: /document.write/gi, type: DOM_MANIPULATION, severity: MEDIUM            ]                        return dangerousPatterns.reduceresult, pattern, type, severity =                 const matches = htmlContent.matchpattern                if matches                     result.threats.pu\n\nshtype, severity, matches: matches.length                    result.score += severity === CRITICAL  8 : severity === HIGH  5 : 2                                return result            , score: 0, threats: []            ,        promptInjectionDetection:\n  function detectPromptInjectioncontent             const injectionPatterns = [                /ignores+previouss+instructions/gi,                /yous+ares+nows+as+differents+AI/gi,                /forgets+yours+constraints/gi,                /bypasss+safetys+guidelines/gi            ]                        const detectedPatterns = injectionPatterns.filterpattern = pattern.testcontent            return                 score: detectedPatterns.length  6,                threats: detectedPatterns.mappattern =                     type: PROMPT_INJECTION,                    severity: CRITICAL,                    pattern: pattern.source                ,                confidence: detected\n\nPatterns.length  0  95 : 85                        #\n\n## Repository Analysis Engine\n\njavascriptconst REPOSITORY_ANALYSIS_FUNCTIONS =     dependencyVulnerabilityScanner:\n  function scanDependencyVulnerabilitiespackageData             // Analyze package.json, requirements.txt, etc.            const vulnerablePatterns = [                name: loda\n\nsh, versions: [4.17.21], severity: HIGH,                name: axios, versions: [0.21.1], severity: MEDIUM            ]                        return vulnerablePatterns.reduceresult, vuln =                 if packageData.dependencies  packageData.dependencies[vuln.name]                     result.threats.pu\n\nsh                        type: VULNERABLE_DEPENDENCY,                        package: vuln.name,                        severity: vuln.severity                                        result.score += vuln.severity === HIGH  4 : 2                                return result            , score: 0, threats: []            ,        maliciousCodeDetection:\n  function detectMaliciousCodesourceCode             const suspiciousPatterns = [                pattern: /execssystems/gi, type: COMMAND_EXECUTION, severity: CRITICAL,                pattern: /passwords=s[][^]+[]/gi, type: HARDCODED_CREDENTIALS, severity: HIGH,                pattern: /.exebatcmds/gim, type: EXECUTABLE_FILE, severity: MEDIUM            ]                        return suspiciousPatterns.reduceresult, pattern, type, severity =                 const matches = source\n\nCode.matchpattern                if matches                     result.threats.pu\n\nshtype, severity, count: matches.length                    result.score += severity === CRITICAL  7 : severity === HIGH  4 : 2                                return result            , score: 0, threats: []            #\n\n# Integration with DollhouseMCP Skills\n\n### Skill Coordination Protocol\n\nyamlskill_integration:\n  pre_analysis:\n  encoding_pattern_detection:\n  purpose: identify_encoded_content      input: raw_content_sample        output: encoding_flags, decoded_preview        during_analysis:\n  content_safety_validator:\n  purpose: pattern_matching_supplement      input: programmatic_analysis_results      output: additional_threat_indicators        post_analysis:\n  web_content_analyzer:\n  purpose: contextual_enhancement      input: javascript_analysis_output      output: behavioral_pattern_assessment\n\n### Agent Collaboration Framework\n\nyamlagent_coordination:\n  security_workflow_orchestrator:\n  role: master_coordinator    data_exchange:\n  - receives: programmatic_analysis_results\n\n- provides: user_context_data, workflow_preferences\n\n- coordinates: notification_timing, response_escalation        jailbreak_detection_agent:\n  role: specialized_threat_responder    data_exchange:\n  - receives: prompt_injection_detection_results\n\n- provides: behavioral_context, historical_patterns\n\n- coordinates: immediate_threat_response, user_education\n\n## Execution Templates and Workflows\n\n### Standard Web Analysis Workflow\n\nyamlweb_analysis_execution:\n  step_1_data_collection:\n  javascript:\n  const response = await fetchtargetUrl      const html = await response.text      const headers = Object.fromEntriesresponse.headers.entries        step_2_security_analysis:\n  javascript:\n  const securityResults =         headers: validateSecurityHeader\n\nsheaders,        scripts: detectMaliciousScript\n\nshtml,        injection: detectPromptInjectionhtml              step_3_risk_calculation:\n  javascript:\n  const totalRisk = Object.valuessecurityResults        .reducesum, result = sum + result.score  0, 0      const classification = classifyRiskLeveltotalRisk        step_4_response_generation:\n  javascript:\n  return generateSecurityResponseclassification, security\n\nResults\n\n### Repository Analysis Workflow  yamlrepository_analysis_execution:\n  step_1_structure_analysis:\n  javascript:\n  const repoStructure = await analyzeRepositoryStructurerepoUrl      const suspiciousFiles = identifySuspiciousFilesrepoStructure.files        step_2_code_security_scan:\n  javascript:\n  const codeAnalysis = await scanSourceCodeSecurityrepoStructure.sourceFiles      const dependencyAnalysis = await analyzeDependenciesrepoStructure.manifests        step_3_threat_assessment:\n  javascript:\n  const combinedResults = consolidateAnalysisResults[        codeAnalysis, dependencyAnalysis, suspicious\n\nFiles      ]\n\n## Performance and Accuracy Metrics\n\n### Real-Time Performance Monitoring\n\nyamlperformance_metrics:\n  analysis_speed:\n  target_web_analysis: 5_seconds    target_repo_analysis: 15_seconds      target_ai_tool_analysis: 8_seconds      accuracy_measures:\n  true_positive_rate: 92%    false_positive_rate: 6%    confidence_calibration: Â±3%      resource_efficiency:\n  memory_usage: 50MB    cpu_utilization: 20%    network_requests: minimal\n\n### Continuous Improvement Framework\n\nyamllearning_mechanisms:\n  pattern_refinement:\n  - analyze_false_positives: adjust_thre\n\nsholds, refine_patterns\n\n- incorporate_new_threats: update_detection_rules, expand_databases\n\n- optimize_performance: streamline_analysis, cache_results      user_feedback_integration:\n  - accuracy_feedback: Was this assessment correct\n\n- severity_feedback: Was the risk level appropriate\n\n- recommendation_feedback: Were the suggestions helpful      threat_intelligence_updates:\n  - security_research_integration: new_vulnerability_patterns\n\n- community_threat_sharing: anonymized_detection_patterns\n\n- vendor_security_advisories: official_vulnerability_disclosures\n\n## Emergency Response and Failsafe Systems\n\n### Critical Threat Response\n\nyamlemergency_protocols:\n  zero_day_detection:\n  trigger: unknown_critical_pattern_detected    action: immediate_isolation_and_analysis    escalation: security_team_notification      analysis_system_compromise:\n  trigger: integrity_check_failure    action: fallback_to_conservative_blocking    escalation: system_administrator_alert      false_positive_storm:\n  trigger: fp_rate  15% in 1_hour    action: reduce_sensitivity_temporarily    escalation: manual_review_required\n\nThis agent provides the foundation for executing real programmatic security analysis while integrating seamlessly with the broader DollhouseMCP security ecosystem, giving you precise, measurable security validation with full transparency and continuous improvement capabilities.\n"
    }
  },
  "summary": {
    "totalFiles": 1,
    "criticalIssues": 0,
    "highIssues": 7,
    "mediumIssues": 4,
    "lowIssues": 0,
    "overallScore": 90,
    "riskLevel": "HIGH"
  },
  "timestamp": "2025-10-25T20:29:35.030Z"
}